{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: matplotlib in e:\\aditya\\python\\lib\\site-packages (3.7.5)\n",
      "Requirement already satisfied: numpy in e:\\aditya\\python\\lib\\site-packages (1.24.3)\n",
      "Requirement already satisfied: scikit-learn in e:\\aditya\\python\\lib\\site-packages (1.3.2)\n",
      "Requirement already satisfied: opencv-python in e:\\aditya\\python\\lib\\site-packages (4.9.0.80)\n",
      "Requirement already satisfied: tensorflow[and-cuda] in e:\\aditya\\python\\lib\\site-packages (2.13.0)\n",
      "Requirement already satisfied: pandas in e:\\aditya\\python\\lib\\site-packages (2.0.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\adity\\appdata\\roaming\\python\\python38\\site-packages (from matplotlib) (2.8.2)\n",
      "Requirement already satisfied: cycler>=0.10 in e:\\aditya\\python\\lib\\site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: importlib-resources>=3.2.0 in e:\\aditya\\python\\lib\\site-packages (from matplotlib) (6.4.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in e:\\aditya\\python\\lib\\site-packages (from matplotlib) (1.1.1)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in e:\\aditya\\python\\lib\\site-packages (from matplotlib) (3.1.2)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in e:\\aditya\\python\\lib\\site-packages (from matplotlib) (1.4.5)\n",
      "Requirement already satisfied: pillow>=6.2.0 in e:\\aditya\\python\\lib\\site-packages (from matplotlib) (10.3.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\adity\\appdata\\roaming\\python\\python38\\site-packages (from matplotlib) (23.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in e:\\aditya\\python\\lib\\site-packages (from matplotlib) (4.51.0)\n",
      "Requirement already satisfied: zipp>=3.1.0 in c:\\users\\adity\\appdata\\roaming\\python\\python38\\site-packages (from importlib-resources>=3.2.0->matplotlib) (3.15.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\adity\\appdata\\roaming\\python\\python38\\site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in e:\\aditya\\python\\lib\\site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in e:\\aditya\\python\\lib\\site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: scipy>=1.5.0 in e:\\aditya\\python\\lib\\site-packages (from scikit-learn) (1.10.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in e:\\aditya\\python\\lib\\site-packages (from scikit-learn) (3.4.0)\n",
      "Requirement already satisfied: joblib>=1.1.1 in e:\\aditya\\python\\lib\\site-packages (from scikit-learn) (1.4.0)\n",
      "Requirement already satisfied: tensorflow-intel==2.13.0 in e:\\aditya\\python\\lib\\site-packages (from tensorflow[and-cuda]) (2.13.0)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in e:\\aditya\\python\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow[and-cuda]) (0.31.0)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in e:\\aditya\\python\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow[and-cuda]) (4.25.3)\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in e:\\aditya\\python\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow[and-cuda]) (0.4.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in e:\\aditya\\python\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow[and-cuda]) (3.10.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in e:\\aditya\\python\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow[and-cuda]) (1.16.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in e:\\aditya\\python\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow[and-cuda]) (0.2.0)\n",
      "Requirement already satisfied: setuptools in e:\\aditya\\python\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow[and-cuda]) (47.1.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in e:\\aditya\\python\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow[and-cuda]) (1.6.3)\n",
      "Requirement already satisfied: libclang>=13.0.0 in e:\\aditya\\python\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow[and-cuda]) (18.1.1)\n",
      "Requirement already satisfied: typing-extensions<4.6.0,>=3.6.6 in e:\\aditya\\python\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow[and-cuda]) (4.5.0)\n",
      "Requirement already satisfied: keras<2.14,>=2.13.1 in e:\\aditya\\python\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow[and-cuda]) (2.13.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in e:\\aditya\\python\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow[and-cuda]) (3.3.0)\n",
      "Requirement already satisfied: tensorboard<2.14,>=2.13 in e:\\aditya\\python\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow[and-cuda]) (2.13.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in e:\\aditya\\python\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow[and-cuda]) (2.1.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in e:\\aditya\\python\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow[and-cuda]) (2.4.0)\n",
      "Requirement already satisfied: flatbuffers>=23.1.21 in e:\\aditya\\python\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow[and-cuda]) (24.3.25)\n",
      "Requirement already satisfied: tensorflow-estimator<2.14,>=2.13.0 in e:\\aditya\\python\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow[and-cuda]) (2.13.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in e:\\aditya\\python\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow[and-cuda]) (1.62.1)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in e:\\aditya\\python\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.13.0->tensorflow[and-cuda]) (0.43.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in e:\\aditya\\python\\lib\\site-packages (from tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow[and-cuda]) (1.0.0)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in e:\\aditya\\python\\lib\\site-packages (from tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow[and-cuda]) (2.31.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in e:\\aditya\\python\\lib\\site-packages (from tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow[and-cuda]) (3.6)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in e:\\aditya\\python\\lib\\site-packages (from tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow[and-cuda]) (1.0.1)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in e:\\aditya\\python\\lib\\site-packages (from tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow[and-cuda]) (2.29.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in e:\\aditya\\python\\lib\\site-packages (from tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow[and-cuda]) (0.7.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in e:\\aditya\\python\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow[and-cuda]) (0.4.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in e:\\aditya\\python\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow[and-cuda]) (4.9)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in e:\\aditya\\python\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow[and-cuda]) (5.3.3)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in e:\\aditya\\python\\lib\\site-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow[and-cuda]) (2.0.0)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in c:\\users\\adity\\appdata\\roaming\\python\\python38\\site-packages (from markdown>=2.6.8->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow[and-cuda]) (6.6.0)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in e:\\aditya\\python\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow[and-cuda]) (0.6.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in e:\\aditya\\python\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow[and-cuda]) (2024.2.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in e:\\aditya\\python\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow[and-cuda]) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in e:\\aditya\\python\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow[and-cuda]) (2.2.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in e:\\aditya\\python\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow[and-cuda]) (3.6)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in e:\\aditya\\python\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow[and-cuda]) (3.2.2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: tensorflow 2.13.0 does not provide the extra 'and-cuda'\n",
      "WARNING: You are using pip version 21.0.1; however, version 24.0 is available.\n",
      "You should consider upgrading via the 'e:\\Aditya\\Python\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "!python -m pip install matplotlib numpy scikit-learn opencv-python tensorflow[and-cuda] pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence_length = 20\n",
    "spectrogram_height = 217\n",
    "spectrogram_width = 50\n",
    "latent_dim = 128\n",
    "num_classes = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import regularizers\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from itertools import product\n",
    "import pandas as pd\n",
    "\n",
    "def create_cnn_model(val_kernel_regularizer, num_filters):\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(layers.Conv2D(num_filters[0], (3, 3), activation='relu', input_shape=(spectrogram_height, spectrogram_width, 1), kernel_regularizer=regularizers.l2(2*val_kernel_regularizer)))\n",
    "    model.add(layers.MaxPooling2D((2, 2)))\n",
    "    model.add(layers.Conv2D(num_filters[1], (3, 3), activation='relu', kernel_regularizer=regularizers.l2(2*val_kernel_regularizer)))\n",
    "    model.add(layers.MaxPooling2D((2, 2)))\n",
    "    model.add(layers.Conv2D(num_filters[2], (3, 3), activation='relu', kernel_regularizer=regularizers.l2(val_kernel_regularizer)))\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dense(latent_dim, activation='relu', kernel_regularizer=regularizers.l2(val_kernel_regularizer)))\n",
    "    return model\n",
    "\n",
    "def create_attention_model(sequence_length, latent_dim, num_attention_heads):\n",
    "    inputs = tf.keras.Input(shape=(sequence_length, latent_dim))\n",
    "    attention_heads = []\n",
    "    for _ in range(num_attention_heads):\n",
    "        attention_head = layers.Attention()([inputs, inputs])\n",
    "        attention_heads.append(attention_head)\n",
    "    attention_concat = layers.Concatenate()(attention_heads)\n",
    "    attention_output = layers.Dense(latent_dim, activation='relu')(attention_concat)\n",
    "    return tf.keras.Model(inputs=inputs, outputs=attention_output)\n",
    "\n",
    "def create_classification_model(sequence_length, latent_dim, num_classes, num_attention_heads):\n",
    "    inputs = tf.keras.Input(shape=(sequence_length, latent_dim))\n",
    "    attention_model = create_attention_model(sequence_length, latent_dim, num_attention_heads)\n",
    "    attention_output = attention_model(inputs)\n",
    "    classification_output = layers.Dense(num_classes, activation='softmax')(attention_output[:, -1, :])\n",
    "    return tf.keras.Model(inputs=inputs, outputs=classification_output)\n",
    "\n",
    "def create_model(sequence_length, spectrogram_height, spectrogram_width, latent_dim, num_classes, num_attention_heads, num_filters, val_kernel_regularizer):\n",
    "    cnn_model = create_cnn_model(val_kernel_regularizer, num_filters)\n",
    "    classification_model = create_classification_model(sequence_length, latent_dim, num_classes, num_attention_heads)\n",
    "    inputs = tf.keras.Input(shape=(sequence_length, spectrogram_height, spectrogram_width, 1))\n",
    "    token_embeddings = layers.TimeDistributed(cnn_model)(inputs)\n",
    "    classification_output = classification_model(token_embeddings)\n",
    "    return tf.keras.Model(inputs=inputs, outputs=classification_output)\n",
    "\n",
    "def train(model, X_train, y_train, X_val, y_val, reduce_factor, reduce_patience, epochs=20, batch_size=32):\n",
    "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=reduce_factor, patience=reduce_patience)\n",
    "    history = model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size, validation_data=(X_val, y_val), callbacks=[reduce_lr])\n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "input_dir = 'E:\\\\Aditya\\\\IIT_Hyderabad\\\\Assignments\\\\Deep Learning\\\\Project\\\\Data\\\\images_cropped_vertical'\n",
    "\n",
    "\n",
    "spectrogram_height = 217\n",
    "spectrogram_width = 50\n",
    "X_train = []\n",
    "y_train = []\n",
    "\n",
    "for label, genre_folder in enumerate(os.listdir(input_dir)):\n",
    "    genre_path = os.path.join(input_dir, genre_folder)\n",
    "    if not os.path.isdir(genre_path):\n",
    "        continue\n",
    "\n",
    "    genre_x = []\n",
    "    genre_y = []\n",
    "    for number, filename in enumerate(os.listdir(genre_path)):\n",
    "        img_path = os.path.join(genre_path, filename)\n",
    "        img = cv2.imread(img_path)\n",
    "        if img is None:\n",
    "            continue\n",
    "        img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        img_resized = cv2.resize(img_gray, (spectrogram_width, spectrogram_height))\n",
    "\n",
    "        genre_x.append(img_resized)\n",
    "        genre_y.append(label)\n",
    "        if ((number + 1)%20 == 0):\n",
    "            X_train.append(genre_x)\n",
    "            genre_x = []\n",
    "            genre_y = []\n",
    "            y_train.append(label)\n",
    "\n",
    "\n",
    "X_train = np.array(X_train)\n",
    "y_train = np.array(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (999, 20, 217, 50)\n",
      "y_train shape: (999,)\n"
     ]
    }
   ],
   "source": [
    "shuffle_indices = np.arange(X_train.shape[0])\n",
    "np.random.shuffle(shuffle_indices)\n",
    "X_train = X_train[shuffle_indices]\n",
    "y_train = y_train[shuffle_indices]\n",
    "print(\"X_train shape:\", X_train.shape)\n",
    "print(\"y_train shape:\", y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "\n",
    "train_data = 'E:\\\\Aditya\\\\IIT_Hyderabad\\\\Assignments\\\\Deep Learning\\\\Project\\\\Data\\\\train_data'\n",
    "os.makedirs(train_data, exist_ok=True)\n",
    "\n",
    "np.save(os.path.join(train_data, 'X_train.npy'), X_train)\n",
    "np.save(os.path.join(train_data, 'y_train.npy'), y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in e:\\aditya\\python\\lib\\site-packages (2.0.3)\n",
      "Requirement already satisfied: numpy>=1.20.3 in e:\\aditya\\python\\lib\\site-packages (from pandas) (1.24.3)\n",
      "Requirement already satisfied: tzdata>=2022.1 in e:\\aditya\\python\\lib\\site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\adity\\appdata\\roaming\\python\\python38\\site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in e:\\aditya\\python\\lib\\site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\adity\\appdata\\roaming\\python\\python38\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 21.0.1; however, version 24.0 is available.\n",
      "You should consider upgrading via the 'e:\\Aditya\\Python\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "!python -m pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_filters_list = [(32, 64, 64), (32, 64, 128)]\n",
    "kernel_regularizers = [0.005, 0.01, 0.02]\n",
    "num_attention_heads_list = [2, 4, 6]\n",
    "batch_sizes = [32, 64]\n",
    "results = []\n",
    "\n",
    "\n",
    "for num_filters, kernel_regularizer, num_attention_heads, batch_size in product(num_filters_list, kernel_regularizers, num_attention_heads_list, batch_sizes):\n",
    "    best_val_accuracies = []\n",
    "    best_model_weights = []\n",
    "    for train_index, val_index in StratifiedKFold(n_splits=5).split(X_train, y_train):\n",
    "        X_train_fold, X_val_fold = X_train[train_index], X_train[val_index]\n",
    "        y_train_fold, y_val_fold = y_train[train_index], y_train[val_index]\n",
    "\n",
    "        model = create_model(sequence_length, spectrogram_height, spectrogram_width, latent_dim, num_classes, num_attention_heads, num_filters, kernel_regularizer)\n",
    "        history = train(model, X_train_fold, y_train_fold, X_val_fold, y_val_fold, reduce_factor = 0.2, reduce_patience = 4, epochs = 15, batch_size = batch_size)\n",
    "    \n",
    "        _, val_accuracy = model.evaluate(X_val_fold, y_val_fold)\n",
    "        best_val_accuracies.append(val_accuracy)\n",
    "        model_weights = model.get_weights()\n",
    "        best_model_weights.append(model_weights)\n",
    "        results.append({\n",
    "                    'Num Filters': num_filters,\n",
    "                    'Kernel Regularizer': kernel_regularizer,\n",
    "                    'Num Attention Heads': num_attention_heads,\n",
    "                    'Batch Size': batch_size,\n",
    "                    'Validation Accuracy': val_accuracy\n",
    "                })\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = pd.DataFrame(results)\n",
    "results_df = results_df.sort_values(by='Validation Accuracy', ascending=False)\n",
    "pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Num Filters</th>\n",
       "      <th>Kernel Regularizer</th>\n",
       "      <th>Num Attention Heads</th>\n",
       "      <th>Batch Size</th>\n",
       "      <th>Validation Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(32, 64, 64)</td>\n",
       "      <td>0.005</td>\n",
       "      <td>4</td>\n",
       "      <td>32</td>\n",
       "      <td>0.510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(32, 64, 64)</td>\n",
       "      <td>0.005</td>\n",
       "      <td>2</td>\n",
       "      <td>64</td>\n",
       "      <td>0.510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>(32, 64, 128)</td>\n",
       "      <td>0.020</td>\n",
       "      <td>4</td>\n",
       "      <td>64</td>\n",
       "      <td>0.500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(32, 64, 64)</td>\n",
       "      <td>0.005</td>\n",
       "      <td>4</td>\n",
       "      <td>64</td>\n",
       "      <td>0.485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>(32, 64, 128)</td>\n",
       "      <td>0.005</td>\n",
       "      <td>4</td>\n",
       "      <td>32</td>\n",
       "      <td>0.485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>(32, 64, 128)</td>\n",
       "      <td>0.005</td>\n",
       "      <td>6</td>\n",
       "      <td>64</td>\n",
       "      <td>0.485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>(32, 64, 128)</td>\n",
       "      <td>0.005</td>\n",
       "      <td>4</td>\n",
       "      <td>64</td>\n",
       "      <td>0.475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>(32, 64, 64)</td>\n",
       "      <td>0.010</td>\n",
       "      <td>2</td>\n",
       "      <td>32</td>\n",
       "      <td>0.470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>(32, 64, 128)</td>\n",
       "      <td>0.010</td>\n",
       "      <td>4</td>\n",
       "      <td>64</td>\n",
       "      <td>0.470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>(32, 64, 64)</td>\n",
       "      <td>0.010</td>\n",
       "      <td>6</td>\n",
       "      <td>64</td>\n",
       "      <td>0.465</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Num Filters  Kernel Regularizer  Num Attention Heads  Batch Size  \\\n",
       "2    (32, 64, 64)               0.005                    4          32   \n",
       "1    (32, 64, 64)               0.005                    2          64   \n",
       "33  (32, 64, 128)               0.020                    4          64   \n",
       "3    (32, 64, 64)               0.005                    4          64   \n",
       "20  (32, 64, 128)               0.005                    4          32   \n",
       "23  (32, 64, 128)               0.005                    6          64   \n",
       "21  (32, 64, 128)               0.005                    4          64   \n",
       "6    (32, 64, 64)               0.010                    2          32   \n",
       "27  (32, 64, 128)               0.010                    4          64   \n",
       "11   (32, 64, 64)               0.010                    6          64   \n",
       "\n",
       "    Validation Accuracy  \n",
       "2                 0.510  \n",
       "1                 0.510  \n",
       "33                0.500  \n",
       "3                 0.485  \n",
       "20                0.485  \n",
       "23                0.485  \n",
       "21                0.475  \n",
       "6                 0.470  \n",
       "27                0.470  \n",
       "11                0.465  "
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model_row  = results_df.loc[results_df['Validation Accuracy'].idxmax()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduce_factor_list = [0.2, 0.3]\n",
    "reduce_patience_list = [4, 6]\n",
    "results_reduce = []\n",
    "\n",
    "for reduce_factor, reduce_patience in product(reduce_factor_list, reduce_patience_list):\n",
    "    best_val_accuracies = []\n",
    "    best_model_weights = []\n",
    "    for train_index, val_index in StratifiedKFold(n_splits=8).split(X_train, y_train):\n",
    "        X_train_fold, X_val_fold = X_train[train_index], X_train[val_index]\n",
    "        y_train_fold, y_val_fold = y_train[train_index], y_train[val_index]\n",
    "\n",
    "        model = create_model(sequence_length, spectrogram_height, spectrogram_width, latent_dim, num_classes, best_model_row['Num Attention Heads'], best_model_row['Num Filters'], best_model_row['Kernel Regularizer'])\n",
    "        history = train(model, X_train_fold, y_train_fold, X_val_fold, y_val_fold, reduce_factor, reduce_patience, epochs = 20, batch_size = best_model_row['Batch Size'])\n",
    "        \n",
    "        _, val_accuracy = model.evaluate(X_val_fold, y_val_fold)\n",
    "        best_val_accuracies.append(val_accuracy)\n",
    "        \n",
    "        # Save the weights of the model\n",
    "        model_weights = model.get_weights()\n",
    "        best_model_weights.append(model_weights)\n",
    "        results_reduce.append({\n",
    "                    'Reduce Factor': reduce_factor,\n",
    "                    'Reduce Patience': reduce_patience,\n",
    "                })\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Model Parameters:\n",
      "Number of Filters: (32, 64, 64)\n",
      "Kernel Regularizer Value: 0.005\n",
      "Number of Attention Heads: 4\n",
      "Batch Size: 32\n",
      "Reduce Factor: 0.3\n",
      "Reduce Patience: 6\n"
     ]
    }
   ],
   "source": [
    "print(f\"Best Model Parameters:\\nNumber of Filters: {best_model_row['Num Filters']}\\nKernel Regularizer Value: {best_model_row['Kernel Regularizer']}\\nNumber of Attention Heads: {best_model_row['Num Attention Heads']}\\nBatch Size: {best_model_row['Batch Size']}\\nReduce Factor: 0.3\\nReduce Patience: 6\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
